%% Simulating fMRI data with some signal embedded
% The objective is to create a small dataset, that has some signal embedded
% within it, and then use a technique such as lasso to recover the signal
% you put there. For this, you are going to use a function for generating
% random data: 
%doc randn

ntrials = 20;
nvoxels = 40;
X = randn(ntrials,nvoxels);

size(X);

% This created a matrix filled with random numbers---but not just any
% random numbers. Random numbers samples from a normal distribution
% centered on zero with a standard deviation of one. This means that
% numbers closer to zero are more likely than numbers that are far from
% zero (either positive or negative.
% q = -3:.01:3; % ``quantile''
% m = 0;        % mean
% s = 1;        % standard deviation
% plot(q,pdf('norm',q,m,s))
% % 1 SD from the mean
% sd1 = pdf('norm',1,m,s);
% line([1 1],[0,sd1],'Color',[1,0,0],'LineStyle','--');
% line([-3 1],[sd1,sd1],'Color',[1,0,0],'LineStyle','--');
% 
% sd2 = pdf('norm',2,m,s);
% line([2 2],[0,sd2],'Color',[0,1,0],'LineStyle','--');
% line([-3 2],[sd2,sd2],'Color',[0,1,0],'LineStyle','--');

% So, the probability of a value 2 away from zero is about 0.05, and the
% probabilty of a number 1 away from zero is about .25.

% This is important to keep in mind, because understanding the distribution
% of the noise is key to having control over how strong the signal you
% create is.

% For a simple case, let's say the first voxel activates for the first 10
% items, and the second voxel activates for the seconds 10 items, and
% everything else is just left alone (i.e., activating randomly).

X(1:10,1) = X(1:10,1) + 1;
X(11:20,2) = X(11:20,2) + 1;

% Think for a moment---is this signal strong or weak? What is the
% probability of a value being 1 or greater, given the distribution of the
% noise? In the full dataset, what proportion of the voxels carry signal? 

    % Q: The signals are relatively weak. The activiation values were
    % generated by randn, and the data set has mean=0 and std=1. In the
    % normal distribution, there are about 16% of voxels will have the
    % activation values that higher than 1 std just by chance. If the
    % original signals are centered around 0, adding 1 std to the
    % activation value is not going to make them very strong.

% Think also---what do you think would be a good method for recovering this
% data? What if you just contrasted the activation of the first 10 rows
% with the activation of the second 10 rows for each column? 

% Before running any analyses, save your X matrix so that you can get back
% to it later. Read the manual if necessary.
%doc save

% Now, for the sake of it, clear X from the workspace and load it back in.
%doc clear
%doc load

%  Now: run a t-test at each voxel. That is, for each voxel,
%  compare the activation for the first 10 rows to the second 10 rows.
%  Indicate any voxels that show a significant difference.
%doc ttest

% For each voxel, do t-test for the 1st 10 rows with the 2nd 10 rows.
h = ttest(X(1:10,:), X(11:20,:))


% or, if you understand the relationship between regression and t-tests
%doc fitglm 

% This might be tricky to wrap your head around at first, but you can do a
% t-test with a regression model. The outcome variable is the activation
% itself, and you are trying to predict that activation using the row
% labels (which you would need to generate).

RowLabels = zeros(20,1);
RowLabels(1:10,1) = 1;


%  Now try logistic regression. First---how will you need to set up this
%  problem? You will need an additional variable before you can do logistic
%  regression.
%doc fitglm; 
% look under family for binomial. Logistic regression uses a binomial
% distribution.
[b,dev,stats] = glmfit(X, RowLabels, 'binomial', 'link', 'logit')

    % Note: Logistic regression uses all voxels, and row labels should be a
    % column vector, as the labels don't change. 
    
%  As you might have expected, logistic regression doesn't work. Can you
%  explain why?

%  Now, give LASSO a shot. Use glmnet() to fit LASSO to your fake data.
fit = glmnet(X, RowLabels, 'binomial')


(X * fit.beta) + repmat(fit.a0, 20,1) > 0   % prediction
(X * fit.beta) + repmat(fit.a0, 20,1) > 0 % how well does the prediction fits the truth
(X * fit.beta(:,2)) + fit.a0(2)         % look at individual lamda
(X * fit.beta(:,2)) + fit.a0(2) > 0     % look at how this lamda fits the truth
fit.df                                  % How many voxels were selected for each lambda
sum(abs(fit.beta)>0)                    % same as above
fit.lambda                              % lambda values

predictions = (X * fit.beta) + repmat(fit.a0, 20,1) > 0   % prediction
repmat(RowLabels,1,100) == predictions          % compare prediction with truth
mean(repmat(RowLabels,1,100) == predictions)'   % accuracy

imagesc(fit.beta)       % two ways of visualize voxel selection process
glmnetPlot(fit)